<def f='tvm/relay/transforms/higher_order_gradient.cc' l='68' ll='73' type='tvm::relay::Type tvm::relay::WithGradientType(const tvm::relay::Type &amp; t)'/>
<doc f='tvm/relay/transforms/higher_order_gradient.cc' l='58'>/*! In relay, automatic differentiation(AD) is a macro,
 *  that transform closed expr(expr without free variable/free type variable) of type
 *  (x0, x1, x2, ...) -&gt; Float[] to
 *  (x0, x1, x2, ...) -&gt; (Float[], (x0, x1,  x2, ...)),
 *  When x0, x1, x2... are Float of different shape.
 * the return value is a pair, with left hand side as the original value, and right hand side as
 * gradient of the input. WithGradientType will take the type of input, and produce the type of
 * output. There are multiple implementation of AD in relay, with different characteristic. However,
 * they all transform the input expr according to WithGradientType.
 */</doc>
