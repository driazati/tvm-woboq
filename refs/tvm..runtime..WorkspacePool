<def f='tvm/runtime/workspace_pool.h' l='45' ll='77'/>
<ovr f='tvm/runtime/cpu_device_api.cc' l='91' c='tvm::runtime::CPUWorkspacePool'/>
<use f='tvm/runtime/cpu_device_api.cc' l='91'/>
<use f='tvm/runtime/cpu_device_api.cc' l='92' c='_ZN3tvm7runtime16CPUWorkspacePoolC1Ev'/>
<size>40</size>
<doc f='tvm/runtime/workspace_pool.h' l='34'>/*!
 * \brief A workspace pool to manage
 *
 *  \note We have the following assumption about backend temporal
 *   workspace allocation, and will optimize for such assumption,
 *   some of these assumptions can be enforced by the compiler.
 *
 *  - Only a few allocation will happen, and space will be released after use.
 *  - The release order is usually in reverse order of allocate
 *  - Repeative pattern of same allocations over different runs.
 */</doc>
<fun r='_ZN3tvm7runtime13WorkspacePoolC1E12DLDeviceTypePNS0_9DeviceAPIE'/>
<fun r='_ZN3tvm7runtime13WorkspacePoolD1Ev'/>
<fun r='_ZN3tvm7runtime13WorkspacePool14AllocWorkspaceE8DLDevicem'/>
<fun r='_ZN3tvm7runtime13WorkspacePool13FreeWorkspaceE8DLDevicePv'/>
<mbr r='tvm::runtime::WorkspacePool::array_' o='0' t='std::vector&lt;Pool *&gt;'/>
<mbr r='tvm::runtime::WorkspacePool::device_type_' o='192' t='DLDeviceType'/>
<mbr r='tvm::runtime::WorkspacePool::device_' o='256' t='tvm::runtime::DeviceAPI *'/>
